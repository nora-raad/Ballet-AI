# Athletic Position Detection System
# Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÙˆØ²ÛŒØ´Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ ÙˆØ±Ø²Ø´ÛŒ

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![OpenPose](https://img.shields.io/badge/OpenPose-1.7.0-green.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10+-orange.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

*An AI-powered system for automatic detection and classification of five basic athletic positions using computer vision and machine learning*



</div>


## ğŸ¯ Overview

This project implements an intelligent system for detecting and classifying five basic athletic positions using pose estimation and machine learning. The system provides real-time feedback through an intuitive web interface with Persian language support.

### Key Highlights

- **Dual Pipeline Architecture**: OpenPose for accuracy, MediaPipe for real-time performance
- **71% Test Accuracy**: Robust RandomForest classifier with comprehensive feature engineering
- **Real-time Detection**: Instant feedback within 2 seconds
- **User-Friendly Interface**: Clean Streamlit web app with Persian RTL support
- **Privacy-First**: All processing done locally, no data transmission

---

## âœ¨ Features

### Core Capabilities

- âœ… **Multi-Input Support**
  - Upload pre-recorded videos (MP4, AVI, MOV)
  - Live camera feed for real-time detection
  
- âœ… **Accurate Position Detection**
  - Five position classification (First, Second, Third, Fourth, Fifth)
  - Confidence scoring for predictions
  - Visual feedback with position diagrams

- âœ… **Intelligent Processing**
  - Automatic keypoint extraction
  - ~30 geometric features computed
  - Scale-independent normalization
  - Rule-based refinement for challenging positions

- âœ… **User Experience**
  - Persian language interface (RTL layout)
  - Helpful tips for each position
  - Error handling with clear messages
  - Responsive design

---

## ğŸ¬ Demo

### Video Upload Mode
```
1. Upload video file
2. OpenPose extracts keypoints
3. System predicts position
4. See results with confidence score
```

### Live Camera Mode
```
1. Enable camera access
2. MediaPipe tracks in real-time
3. Hold position for 3 seconds
4. Get instant feedback
```

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INPUT LAYER                        â”‚
â”‚  ğŸ“¹ Video Upload          ğŸ“· Live Camera            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚
             â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   OpenPose     â”‚    â”‚   MediaPipe    â”‚
    â”‚   BODY_25      â”‚    â”‚   33 Points    â”‚
    â”‚   25 keypoints â”‚    â”‚   Real-time    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Feature Extraction  â”‚
            â”‚  utils.py            â”‚
            â”‚  ~30 features        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  StandardScaler      â”‚
            â”‚  Normalization       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  RandomForest        â”‚
            â”‚  Classifier          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Refinement          â”‚
            â”‚  refine_4th_5th()    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Web Interface       â”‚
            â”‚  Streamlit UI        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
Raw Input â†’ Pose Estimation â†’ Feature Extraction â†’ 
Scaling â†’ Classification â†’ Refinement â†’ Output
```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- OpenPose 1.7.0 (for video processing)
- Webcam (for live detection)
- Windows 10/11 (or Linux with modifications)

### Step 1: Clone Repository

```bash
git clone https://github.com/nora-raad/Ballet-AI.git
cd Ballet-AI
```

### Step 2: Install Python Dependencies

```bash
pip install -r requirements.txt
```

**requirements.txt:**
```txt
streamlit==1.28.0
opencv-python==4.8.1
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.0
joblib==1.3.2
mediapipe==0.10.5
streamlit-webrtc==0.47.1
Pillow==10.0.0
av==10.0.0
```

### Step 3: Install OpenPose

1. Download OpenPose 1.7.0 binaries from [official repository](https://github.com/CMU-Perceptual-Computing-Lab/openpose/releases)
2. Extract to a directory (e.g., `C:\openpose`)
3. Update the path in `app.py` line 191:
   ```python
   openpose_bin = r'YOUR_PATH\openpose\bin\OpenPoseDemo.exe'
   ```

### Step 4: Prepare Assets

Ensure you have the following structure:
```
project/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ header.png
â”‚   â”œâ”€â”€ first.png
â”‚   â”œâ”€â”€ second.png
â”‚   â”œâ”€â”€ third.png
â”‚   â”œâ”€â”€ fourth.png
â”‚   â””â”€â”€ fifth.png
â”œâ”€â”€ ballet_rf_model1.pkl
â”œâ”€â”€ ballet_rf_scaler1.pkl
â””â”€â”€ app.py
```

### Step 5: Run the Application

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## ğŸ’» Usage

### Quick Start

1. **Launch Application**
   ```bash
   streamlit run app.py
   ```

2. **Choose Input Mode**
   - Select "Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÛŒØ¯ÛŒÙˆ" (Upload Video) for pre-recorded videos
   - Select "Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø²Ù†Ø¯Ù‡" (Live Camera) for real-time detection

3. **Get Results**
   - View detected position name
   - Check confidence percentage
   - Read helpful tips

### Video Upload

```python
# Supported formats: MP4, AVI, MOV
# Recommended: 640x480 or higher, 30 fps
# Content: Full body visible, especially legs and feet
```

### Live Camera

```python
# Requirements:
# - Good lighting
# - Full body in frame
# - Hold position for 3+ seconds
# - Stable posture
```

---

## ğŸ“Š Dataset

### Data Collection

- **Source**: Video recordings of individuals performing 5 positions
- **Total Samples**: ~1,000-1,500 frames
- **Classes**: 5 balanced classes (0-4)
- **Labeling**: Manual annotation based on position type

### Position Definitions

| Class | Name | Description |
|-------|------|-------------|
| 0 | First | Heels together, toes out in straight line |
| 1 | Second | Feet shoulder-width apart, toes out |
| 2 | Third | One foot front, heel touches middle of back foot |
| 3 | Fourth | Feet separated with visible gap (one foot length) |
| 4 | Fifth | Feet crossed, heel touches toes |

### Data Preprocessing

```python
# OpenPose Pipeline
Videos â†’ OpenPose â†’ JSON keypoints â†’ 
conf_merger.py â†’ preprocess1.py â†’ CSV dataset

# MediaPipe Pipeline
Live captures â†’ MediaPipe landmarks â†’ 
preprocess2.py â†’ CSV dataset
```

---

## ğŸ“ˆ Model Performance

### Overall Metrics

| Metric | Validation | Test |
|--------|-----------|------|
| **Accuracy** | 89.2% | 71.0% |
| **Precision** | 0.88 | 0.73 |
| **Recall** | 0.89 | 0.71 |
| **F1-Score** | 0.88 | 0.70 |

### Per-Class Performance

| Position | Precision | Recall | F1-Score | Support |
|----------|-----------|--------|----------|---------|
| First (0) | 1.00 | 1.00 | 1.00 | 5 |
| Second (1) | 1.00 | 1.00 | 1.00 | 4 |
| Third (2) | 0.83 | 0.83 | 0.83 | 6 |
| Fourth (3) | 0.44 | 0.44 | 0.44 | 9 |
| Fifth (4) | 0.57 | 0.57 | 0.57 | 7 |

### Model Comparison

| Model | Validation Acc | Test Acc | Decision |
|-------|----------------|----------|----------|
| **RandomForest** | 89% | 71% | âœ… Selected |
| SVM (RBF) | 89% | 32% | âŒ Rejected (Overfitting) |

### Feature Importance (Top 10)

```
1. ankle_x_dist           15.2%
2. ankle_dist             14.1%
3. foot_spread            11.3%
4. back_heel_to_front_*    9.8%
5. cross_factor            8.5%
6. foot_y_std              6.7%
7. left_turnout_angle      5.9%
8. right_turnout_angle     5.4%
9. heel_toe_overlap_*      4.8%
10. left_leg_len           4.2%
```

---

## ğŸ“ Project Structure

```
Ballet-AI/
â”‚
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ utils.py                        # Feature extraction utilities
â”œâ”€â”€ conf_merger.py                  # Fix OpenPose multi-person detection
â”‚
â”œâ”€â”€ preprocess1.py                  # OpenPose data preprocessing
â”œâ”€â”€ preprocess2.py                  # MediaPipe data preprocessing
â”‚
â”œâ”€â”€ train_random_forest.py          # RF model training
â”œâ”€â”€ train_svm.py                    # SVM model training (comparison)
â”‚
â”œâ”€â”€ ballet_rf_model1.pkl            # Trained RandomForest (OpenPose)
â”œâ”€â”€ ballet_rf_model2.pkl            # Trained RandomForest (MediaPipe)
â”œâ”€â”€ ballet_rf_scaler1.pkl           # StandardScaler (OpenPose)
â”œâ”€â”€ ballet_rf_scaler2.pkl           # StandardScaler (MediaPipe)
â”‚
â”œâ”€â”€ ballet_svm_model1.pkl           # Trained SVM (comparison)
â”œâ”€â”€ ballet_scaler1.pkl              # SVM scaler
â”‚
â”œâ”€â”€ images/                         # UI assets
â”‚   â”œâ”€â”€ header.png
â”‚   â”œâ”€â”€ first.png
â”‚   â”œâ”€â”€ second.png
â”‚   â”œâ”€â”€ third.png
â”‚   â”œâ”€â”€ fourth.png
â”‚   â””â”€â”€ fifth.png
â”‚
â”œâ”€â”€ data/                           # Temporary processing folder
â”‚   â””â”€â”€ (created at runtime)
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ LICENSE                         # MIT License
```

---

## ğŸ› ï¸ Technologies

### Computer Vision

- **OpenPose 1.7.0**: High-accuracy pose estimation (25 keypoints)
- **MediaPipe 0.10**: Real-time pose tracking (33 landmarks)
- **OpenCV 4.8**: Image processing and video handling

### Machine Learning

- **scikit-learn 1.3**: RandomForest classifier, StandardScaler
- **NumPy 1.24**: Numerical computations
- **Pandas 2.0**: Data manipulation

### Web Framework

- **Streamlit 1.28**: Web interface
- **streamlit-webrtc 0.47**: Real-time video streaming

### Development

- **Python 3.8+**: Core programming language
- **joblib**: Model serialization

---

## ğŸ”§ Challenges & Solutions

### Challenge 1: Multi-Person Detection

**Problem**: OpenPose sometimes split one person into multiple detections

**Solution**: 
```python
# conf_merger.py
- Analyze spatial proximity between detections
- Merge keypoints belonging to same person
- Keep highest confidence scores
```

### Challenge 2: Fourth â†” Fifth Confusion

**Problem**: 50% error rate between positions 4 and 5 (very similar in 2D)

**Solution**:
```python
# refine_fourth_fifth() function
- Measure back_heel_to_front_bigtoe distance
- If < 0.08 â†’ Fifth (heels touching)
- If > 0.12 â†’ Fourth (clear separation)
- Hybrid ML + rule-based approach
```

### Challenge 3: SVM Overfitting

**Problem**: SVM showed severe overfitting (89% â†’ 32%)

**Solution**:
```python
# Selected RandomForest instead
- More stable: 89% â†’ 71%
- Better generalization
- Interpretable feature importance
```

### Challenge 4: Real-time Stability

**Problem**: False detections when moving between positions

**Solution**:
```python
# Implemented stability checks
- Require 3 consecutive valid frames
- Fast reset if keypoints lost (0.3s interval)
- Visibility threshold (0.5)
```

---

## ğŸš€ Future Work

### Short-term Improvements

- [ ] Increase training dataset size (>2000 samples)
- [ ] Add more athletic positions (>5)
- [ ] Implement cross-validation
- [ ] Fine-tune hyperparameters

### Medium-term Enhancements

- [ ] 3D pose estimation (depth camera support)
- [ ] Multi-person detection support
- [ ] Mobile application (Android/iOS)
- [ ] User feedback mechanism

### Long-term Vision

- [ ] Deep learning models (CNN/LSTM)
- [ ] Ensemble methods (RF + SVM + NN)
- [ ] Video sequence analysis (temporal features)
- [ ] Cloud deployment option
- [ ] Integration with sports training apps

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the repository**
   ```bash
   git fork https://github.com/nora-raad/Ballet-AI.git
   ```

2. **Create a feature branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```

3. **Commit changes**
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```

4. **Push to branch**
   ```bash
   git push origin feature/AmazingFeature
   ```

5. **Open a Pull Request**

### Contribution Guidelines

- Follow PEP 8 style guide
- Add docstrings to functions
- Include unit tests
- Update documentation
- Comment your code


---

## ğŸ™ Acknowledgments

### Research & Tools

- **OpenPose**: [CMU Perceptual Computing Lab](https://github.com/CMU-Perceptual-Computing-Lab/openpose)
  - Cao et al., "OpenPose: Realtime Multi-Person 2D Pose Estimation" (2019)
  
- **MediaPipe**: [Google Research](https://google.github.io/mediapipe/)
  - Bazarevsky et al., "BlazePose: On-device Real-time Body Pose Tracking" (2020)
  
- **RandomForest**: Breiman, L., "Random Forests" (2001)
  
- **scikit-learn**: Pedregosa et al., "Scikit-learn: Machine Learning in Python" (2011)

### Inspiration

- Athletic training and position correction systems
- Computer vision applications in sports
- Pose estimation research community

### Special Thanks

- Science and Research Branch, Islamic Azad University, Tehran for their Academic support
- My Thesis advisor DR. Farsad Zamani Boroujeni and committee members
- https://www.youtube.com/@NicholasRenotte for inspiring me to take on this challenging project.

---

## ğŸ“§ Contact

**Nora Raad**
- GitHub: [@nora-raad](https://github.com/nora-raad)
- Email: [nooraraad@gmail.com]
- LinkedIn: [https://www.linkedin.com/in/nora-raad]
- Project Link: [https://github.com/nora-raad/Ballet-AI](https://github.com/nora-raad/Ballet-AI)

---

## ğŸ“Š Project Stats

![GitHub stars](https://img.shields.io/github/stars/nora-raad/Ballet-AI?style=social)
![GitHub forks](https://img.shields.io/github/forks/nora-raad/Ballet-AI?style=social)
![GitHub issues](https://img.shields.io/github/issues/nora-raad/Ballet-AI)
![GitHub pull requests](https://img.shields.io/github/issues-pr/nora-raad/Ballet-AI)

---

## ğŸ”– Citation

If you use this project in your research, please cite:

```bibtex
@misc{raad2024athletic,
  author = {Raad, Nora},
  title = {Athletic Position Detection System using Pose Estimation and Machine Learning},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/nora-raad/Ballet-AI}}
}
```

---

<div align="center">

**Made with â¤ï¸ by [Nora Raad](https://github.com/nora-raad)**

â­ Star this repo if you find it helpful!

[â¬† Back to Top](#athletic-position-detection-system)

</div>
